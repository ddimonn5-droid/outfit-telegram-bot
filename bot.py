import os
import re
import random
import logging
import asyncio
import httpx
import requests
from telegram import Update, InlineKeyboardMarkup, InlineKeyboardButton
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters

# ====== –ö–æ–Ω—Ñ–∏–≥ ======
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
XAI_API_KEY = os.getenv("XAI_API_KEY")
PORT = int(os.getenv("PORT", 8443))
APP_URL = os.getenv("RENDER_EXTERNAL_URL")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ====== –ù–∞–¥—ë–∂–Ω—ã–µ fallback-—Å—Å—ã–ª–∫–∏ (—Ä–µ–∞–ª—å–Ω—ã–µ –º–∞–≥–∞–∑–∏–Ω—ã/—Å—Ç—Ä–∞–Ω–∏—Ü—ã) ======
FALLBACK_OUTFITS_REAL = [
    "üëï –ë–µ–ª–∞—è —Ñ—É—Ç–±–æ–ª–∫–∞ ‚Äî https://www.zara.com/",
    "üëñ –î–∂–∏–Ω—Å—ã ‚Äî https://www.levi.com/",
    "üëü –ö–µ–¥—ã ‚Äî https://www.converse.com/",
    "üß• –ö—É—Ä—Ç–∫–∞ ‚Äî https://www.hm.com/",
    "üéí –†—é–∫–∑–∞–∫ ‚Äî https://www.zalando.com/"
]

# ====== –£—Ç–∏–ª–∏—Ç—ã ======
URL_RE = re.compile(r"(https?://[^\s\)\]\>]+)")
IMAGE_EXT_RE = re.compile(r"\.(?:jpg|jpeg|png|gif|webp|bmp)(?:$|\?)", re.I)

def extract_urls(text: str):
    return URL_RE.findall(text or "")

async def validate_url_head_or_get(url: str, timeout: int = 8) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å URL. –°–Ω–∞—á–∞–ª–∞ HEAD ‚Äî –µ—Å–ª–∏ –Ω–µ –¥–æ–ø—É—Å–∫–∞—é—Ç/–≤–æ–∑–≤—Ä–∞—â–∞—é—Ç 405/403, –¥–µ–ª–∞–µ–º GET (–±–µ–∑ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–µ–ª–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é).
    –¢–∞–∫–∂–µ –∏—Å–∫–ª—é—á–∞–µ–º –ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–µ—Å–ª–∏ –Ω–µ —Ö–æ—Ç–∏–º –∏—Ö).
    """
    if IMAGE_EXT_RE.search(url):
        return False  # –∏—Å–∫–ª—é—á–∞–µ–º –ø—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

    try:
        async with httpx.AsyncClient(timeout=timeout) as client:
            # –ü–æ–ø—Ä–æ–±—É–µ–º HEAD
            try:
                r = await client.head(url, follow_redirects=True)
            except (httpx.HTTPError, httpx.RequestError):
                r = None

            if r is not None and r.status_code == 200:
                # –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏–º content-type ‚Äî –Ω–µ –∫–∞—Ä—Ç–∏–Ω–∫–∞
                ctype = r.headers.get("content-type", "")
                if "image/" in ctype:
                    return False
                return True

            # –µ—Å–ª–∏ HEAD –≤–µ—Ä–Ω—É–ª 405/403/0 –∏–ª–∏ –Ω–µ—É–¥–∞—á–Ω–æ ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º GET —Å –º–∞–ª–µ–Ω—å–∫–∏–º –æ—Ç–≤–µ—Ç–æ–º
            try:
                r2 = await client.get(url, follow_redirects=True, timeout=timeout)
                if r2.status_code == 200:
                    ctype = r2.headers.get("content-type", "")
                    if "image/" in ctype:
                        return False
                    return True
            except Exception:
                return False
    except Exception:
        return False
    return False

async def filter_and_validate_urls(candidates: list[str], needed: int = 5) -> list[str]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø–∏—Å–æ–∫ candidate URLs –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–µ validated (unique) –¥–æ needed.
    """
    out = []
    seen = set()
    # –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    sem = asyncio.Semaphore(20)
    async def check(url):
        async with sem:
            ok = await validate_url_head_or_get(url)
            return url if ok else None

    tasks = [asyncio.create_task(check(u)) for u in candidates]
    for task in asyncio.as_completed(tasks):
        res = await task
        if res:
            if res not in seen:
                seen.add(res)
                out.append(res)
            if len(out) >= needed:
                break
    return out

# ====== Grok –∑–∞–ø—Ä–æ—Å—ã ======
def grok_call(payload: dict) -> dict:
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ Grok (—á–µ—Ä–µ–∑ requests) ‚Äî —Ç.–∫. python-telegram-bot main flow —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ webhook.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç raw json.
    """
    url = "https://api.x.ai/v1/chat/completions"
    headers = {"Authorization": f"Bearer {XAI_API_KEY}", "Content-Type": "application/json"}
    r = requests.post(url, headers=headers, json=payload, timeout=60)
    r.raise_for_status()
    return r.json()

async def grok_outfit_request_raw(user_text: str, max_search_results: int = 8, mode: str = "on") -> dict:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç raw –æ—Ç–≤–µ—Ç Grok (json) ‚Äî –≤–∫–ª—é—á–∞–µ—Ç –ø–æ–ª–µ 'citations' –µ—Å–ª–∏ –µ—Å—Ç—å.
    """
    payload = {
        "model": "grok-4",
        "messages": [
            {"role": "system", "content": (
                "–¢—ã –º–æ–¥–Ω—ã–π —Å—Ç–∏–ª–∏—Å—Ç. –û—Ç–≤–µ—á–∞–π —Å–ø–∏—Å–∫–æ–º –∏–∑ —Ä–æ–≤–Ω–æ 5 –ø—É–Ω–∫—Ç–æ–≤: –ù–∞–∑–≤–∞–Ω–∏–µ –≤–µ—â–∏ ‚Äî —Å—Å—ã–ª–∫–∞. "
                "–ò—Å–ø–æ–ª—å–∑—É–π —Ä–µ–∞–ª—å–Ω—ã–µ –æ–Ω–ª–∞–π–Ω-–º–∞–≥–∞–∑–∏–Ω—ã Zara, Lyst, Grailed, Bershka. "
                "–ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω ‚Äî –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —É—Ä–ª—ã, –≤–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –≤–µ—Ä–Ω–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ —Å—Å—ã–ª–∫–∏."
            )},
            {"role": "user", "content": f"–ü–æ–¥–±–µ—Ä–∏ –∞—É—Ç—Ñ–∏—Ç: {user_text}"}
        ],
        "max_tokens": 600,
        "search_parameters": {
            "mode": mode,
            "return_citations": True,
            "max_search_results": max_search_results,
            "sources": [{"type": "web"}, {"type": "news"}]
        },
    }
    # grok_call ‚Äî —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π
    return grok_call(payload)

async def grok_request_only_links(user_text: str, min_links: int = 5, max_search_results: int = 12) -> dict:
    """
    –í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥ ‚Äî –ø—Ä–æ—Å–∏–º Grok –≤–µ—Ä–Ω—É—Ç—å –¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã–µ URL –ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É, –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏–π.
    """
    payload = {
        "model": "grok-4",
        "messages": [
            {"role": "system", "content": "–¢–µ–±–µ –Ω—É–∂–Ω–æ –≤—ã–≤–µ—Å—Ç–∏ —Å—Ç—Ä–æ–≥–æ —Å–ø–∏—Å–æ–∫ —Ä–∞–±–æ—á–∏—Ö URL, –ø–æ –æ–¥–Ω–æ–º—É –≤ —Å—Ç—Ä–æ–∫–µ. –ë–µ–∑ –æ–ø–∏—Å–∞–Ω–∏–π."},
            {"role": "user", "content": f"–ù–∞–π–¥–∏ {min_links} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∏ —Ä–µ–∞–ª—å–Ω—ã—Ö URL (–º–∞–≥–∞–∑–∏–Ω—ã, product pages –∏–ª–∏ —Å—Ç–∞—Ç—å–∏) –ø–æ —Ç–µ–º–µ: {user_text}"}
        ],
        "max_tokens": 300,
        "search_parameters": {
            "mode": "on",
            "return_citations": True,
            "max_search_results": max_search_results,
            "sources": [{"type": "web"}, {"type": "news"}]
        },
        "temperature": 0.0
    }
    return grok_call(payload)

# ====== –ö–æ–º–∞–Ω–¥—ã –±–æ—Ç–∞ ======
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [[InlineKeyboardButton("–ü—Ä–∏–º–µ—Ä: –∫—ç–∂—É–∞–ª", callback_data="casual")],
                [InlineKeyboardButton("–ü–æ–º–æ—â—å", callback_data="help")]]
    await update.message.reply_text(
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç-—Å—Ç–∏–ª–∏—Å—Ç.\n–ù–∞–ø–∏—à–∏ —Å—Ç–∏–ª—å –∏–ª–∏ —Å–∏—Ç—É–∞—Ü–∏—é, –∏ —è –ø–æ–¥–±–µ—Ä—É –∞—É—Ç—Ñ–∏—Ç.",
        reply_markup=InlineKeyboardMarkup(keyboard)
    )

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ù–∞–ø–∏—à–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä: '–æ—Ñ–∏—Å –ª–µ—Ç–æ–º' –∏–ª–∏ '–≤–µ—á–µ—Ä–∏–Ω–∫–∞ –≤ —Å—Ç–∏–ª–µ 90-—Ö'.\n"
        "–Ø –≤–µ—Ä–Ω—É –¥–æ 5 —Ä–∞–±–æ—á–∏—Ö —Å—Å—ã–ª–æ–∫ –Ω–∞ –≤–µ—â–∏/—Å—Ç—Ä–∞–Ω–∏—Ü—ã."
    )

# ====== –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π ======
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_text = update.message.text.strip()
    await update.message.reply_text("‚ú® –ò—â—É —Ä–µ–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ —Å—Å—ã–ª–∫–∏...")

    # 1) –ø–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: –æ–±—â–∏–π –æ—Ç–≤–µ—Ç –æ—Ç Grok
    try:
        raw = await grok_outfit_request_raw(user_text)
    except Exception as e:
        logger.exception("Grok call failed")
        await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ø–æ–∏—Å–∫—É. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")
        return

    # 2) —Å–æ–±–∏—Ä–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: —Å–Ω–∞—á–∞–ª–∞ citations (—Å–∞–º—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–µ), –∑–∞—Ç–µ–º —É—Ä–ª—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞
    citations = raw.get("citations") or []
    # –∏–Ω–æ–≥–¥–∞ Grok –æ—Ç–¥–∞—ë—Ç citations –≤ message: msg.get("citations")
    if not citations:
        choice = (raw.get("choices") or [{}])[0]
        msg = choice.get("message") or {}
        citations = msg.get("citations") or raw.get("citations") or []

    text = ""
    choice = (raw.get("choices") or [{}])[0]
    msg = choice.get("message") or {}
    text = msg.get("content") or choice.get("text") or ""

    candidates = []
    # —Å—Ç–∞–≤–∏–º —Ü–∏—Ç–∞—Ç—ã –ø–µ—Ä–≤—ã–º–∏
    for u in citations:
        candidates.append(u)
    # –¥–æ–±–∞–≤–ª—è–µ–º —É—Ä–ª—ã, –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –≤ —Ç–µ–∫—Å—Ç–µ
    for u in extract_urls(text):
        if u not in candidates:
            candidates.append(u)

    # 3) —Ñ–∏–ª—å—Ç—Ä—É–µ–º –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
    validated = await filter_and_validate_urls(candidates, needed=5)

    # 4) –µ—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç ‚Äî –¥–µ–ª–∞–µ–º –≤—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥ "—Ç–æ–ª—å–∫–æ —Å—Å—ã–ª–∫–∏"
    if len(validated) < 5:
        try:
            raw2 = await grok_request_only_links(user_text, min_links=5, max_search_results=12)
            # –±–µ—Ä–µ–º citations –ø–µ—Ä–≤—ã–º–∏
            candidates2 = raw2.get("citations") or []
            if not candidates2:
                choice2 = (raw2.get("choices") or [{}])[0]
                msg2 = choice2.get("message") or {}
                text2 = msg2.get("content") or choice2.get("text") or ""
                candidates2 = extract_urls(text2)
            # –¥–æ–ø–æ–ª–Ω—è–µ–º —Å–ø–∏—Å–∫–æ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ –≤—Ç–æ—Ä–æ–≥–æ –ø—Ä–æ—Ö–æ–¥–∞
            for u in candidates2:
                if u not in candidates:
                    candidates.append(u)
            # –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–Ω–æ–≤–∞ (–∑–∞–º–µ—Ç–∏–º: filter_and_validate_urls –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —É–∂–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å)
            more = await filter_and_validate_urls(candidates, needed=5)
            # –æ–±—ä–µ–¥–∏–Ω—è–µ–º, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫ –≤ more (—ç—Ç–æ —É–∂–µ validated subset)
            # we prefer earlier validated items, so we merge intelligently:
            final = []
            for u in validated + more:
                if u not in final:
                    final.append(u)
                if len(final) >= 5:
                    break
            validated = final
        except Exception:
            logger.exception("Second Grok pass failed")

    # 5) –ï—Å–ª–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç ‚Äî –¥–æ–ø–æ–ª–Ω—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–º–∏ fallback —Å—Å—ã–ª–∫–∞–º–∏
    final_lines = []
    for u in validated:
        final_lines.append(u)
    # If there are less than 5, append FALLBACK_REAL full lines (name ‚Äî url)
    idx = 0
    while len(final_lines) < 5 and idx < len(FALLBACK_OUTFITS_REAL):
        final_lines.append(FALLBACK_OUTFITS_REAL[idx])
        idx += 1

    # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ —Å—Å—ã–ª–∫–∏ (–∫–∞–∂–¥—ã–π –≤ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–µ).
    # –ï—Å–ª–∏ Grok –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –¥–∞–ª –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä "Leather Sneakers ‚Äî https://..."), –º—ã –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º –ø–æ–∫–∞–∑–∞—Ç—å "–ù–∞–∑–≤–∞–Ω–∏–µ ‚Äî URL"
    # –ü–æ—ç—Ç–æ–º—É –ø–æ–ø—Ä–æ–±—É–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å: –µ—Å–ª–∏ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —Å—Ç—Ä–æ–∫–∞, —Å–æ–¥–µ—Ä–∂–∞—â–∞—è –≤–∞–ª–∏–¥ url, –æ—Ç–æ–±—Ä–∞–∑–∏–º –µ—ë.
    out_lines = []
    # map url->line from original text (if applicable)
    url_to_line = {}
    for line in (text or "").splitlines():
        for u in extract_urls(line):
            url_to_line[u] = line.strip()

    for item in final_lines:
        # –µ—Å–ª–∏ —ç—Ç–æ —É–∂–µ "Name ‚Äî url" (–≤ FALLBACK_OUTFITS_REAL) ‚Äî –æ—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ –µ—Å—Ç—å
        if "‚Äî" in item and "http" in item:
            out_lines.append(item)
            continue
        # else item is a url, try find matching descriptive line
        if item in url_to_line:
            out_lines.append(url_to_line[item])
        else:
            # —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –±–∞–∑–æ–≤–æ: —Å—Å—ã–ª–∫–∞ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–µ
            out_lines.append(f"- {item}")

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ/—Ä–µ–∞–ª—å–Ω—ã–µ —Å—Å—ã–ª–∫–∏, –±–µ–∑ –∞–≤—Ç–æ–ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Ç–µ–∫—Å—Ç–∞
    reply = "–í–æ—Ç —á—Ç–æ —è –ø–æ–¥–æ–±—Ä–∞–ª (—Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ —Å—Å—ã–ª–∫–∏):\n\n" + "\n".join(out_lines[:5])
    await update.message.reply_text(reply)

# ====== Main ======
def main():
    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –≤ —Ä–µ–∂–∏–º–µ Webhook...")
    app.run_webhook(
        listen="0.0.0.0",
        port=PORT,
        url_path=TELEGRAM_BOT_TOKEN,
        webhook_url=f"{APP_URL}/{TELEGRAM_BOT_TOKEN}"
    )

if __name__ == "__main__":
    main()
