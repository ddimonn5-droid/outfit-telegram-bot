# bot.py
import os
import re
import time
import logging
import html
import asyncio
import httpx
import requests
from typing import List, Optional, Tuple
from telegram import Update, InlineKeyboardMarkup, InlineKeyboardButton
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters

# ========== CONFIG ==========
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
XAI_API_KEY = os.getenv("XAI_API_KEY")
PORT = int(os.getenv("PORT", 8443))
APP_URL = os.getenv("RENDER_EXTERNAL_URL")  # https://your-service.onrender.com

# Safety checks
if not TELEGRAM_BOT_TOKEN or not XAI_API_KEY:
    raise RuntimeError("Set TELEGRAM_BOT_TOKEN and XAI_API_KEY environment variables")

# ========== LOGGING ==========
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("grok_bot")

# ========== HELPERS / CONSTANTS ==========
URL_RE = re.compile(r"https?://[^\s\)\]\>]+")
IMG_EXT_RE = re.compile(r"\.(?:jpg|jpeg|png|gif|webp|bmp)(?:$|\?)", re.I)
PRODUCT_HINTS = ["product", "productpage", "item", "detail", "p/", "sku", "id=", "prd", "listing", "variant", "/dp/"]  # /dp/ for amazon-like
EMOJIS = ["üëï", "üëñ", "üëü", "üß•", "üéí"]

# Timeout & concurrency
HTTP_TIMEOUT = 10
CONCURRENCY = 16

def clean_url(u: str) -> str:
    """–£–±–∏—Ä–∞–µ–º –Ω–µ–≤–∏–¥–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã, HTML-—ç–Ω—Ç–∏–∫–æ–¥—ã –∏ –∑–∞–≤–µ—Ä—à–∞—é—â–∏–µ –∑–Ω–∞–∫–∏."""
    u = html.unescape(u)
    # remove zero-width spaces etc
    u = u.replace("\u200b", "").replace("\u200e", "").replace("\u200f", "")
    u = u.strip()
    # strip trailing punctuation that often attaches (.,);:)
    while len(u) and u[-1] in ".,;:)]'\"":
        u = u[:-1]
    return u

def extract_urls(text: str) -> List[str]:
    if not text:
        return []
    found = URL_RE.findall(text)
    return [clean_url(u) for u in found]

def looks_like_product(url: str) -> bool:
    url_l = url.lower()
    # must contain some product hint or long slug
    if any(h in url_l for h in PRODUCT_HINTS):
        return True
    # additional heuristic: path length bigger than 2 segments
    try:
        path = requests.utils.urlparse(url).path
        if path and len([p for p in path.split("/") if p]) >= 2:
            return True
    except Exception:
        pass
    return False

# ========== HTTP helpers ==========
async def head_or_get_ok(url: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ –∏ –Ω–µ –∫–∞—Ä—Ç–∏–Ω–∫–∞."""
    if IMG_EXT_RE.search(url):
        return False
    try:
        async with httpx.AsyncClient(timeout=HTTP_TIMEOUT, follow_redirects=True) as client:
            # try GET directly, simpler and more universal
            r = await client.get(url)
            if r.status_code == 200:
                ctype = r.headers.get("content-type", "")
                if "text/html" in ctype:
                    return True
    except Exception as e:
        logger.debug("validate error %s -> %s", url, e)
        return False
    return False

async def fetch_title(url: str) -> Optional[str]:
    """–ü—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å <title> –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    try:
        async with httpx.AsyncClient(timeout=HTTP_TIMEOUT, follow_redirects=True) as client:
            r = await client.get(url)
            if r.status_code != 200:
                return None
            text = r.text
            m = re.search(r"<title[^>]*>(.*?)</title>", text, flags=re.I|re.S)
            if m:
                title = html.unescape(m.group(1)).strip()
                # –∫–æ—Ä–æ—Ç–∫–∞—è —á–∏—Å—Ç–∫–∞
                title = re.sub(r"\s+", " ", title)
                # —É—Ä–µ–∑–∞—Ç—å –¥–ª–∏–Ω–Ω—ã–µ
                return title[:120]
    except Exception as e:
        logger.debug("fetch_title error %s -> %s", url, e)
    return None

async def validate_and_title_batch(urls: List[str], needed: int) -> List[Tuple[str, Optional[str]]]:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –≤–∞–ª–∏–¥–∏—Ä—É–µ–º —É—Ä–ª—ã –∏ –ø–æ–ª—É—á–∞–µ–º title; –≤–æ–∑–≤—Ä–∞—â–∞–µ–º (url, title)."""
    out = []
    seen = set()
    sem = asyncio.Semaphore(CONCURRENCY)

    async def worker(u):
        async with sem:
            ok = await head_or_get_ok(u)
            if not ok:
                return None
            title = await fetch_title(u)
            return (u, title)

    tasks = [asyncio.create_task(worker(u)) for u in urls]
    for t in asyncio.as_completed(tasks):
        try:
            res = await t
        except Exception:
            res = None
        if res:
            url, title = res
            if url not in seen:
                seen.add(url)
                out.append((url, title))
                if len(out) >= needed:
                    break
    return out

# ========== Grok call ==========
def grok_call(payload: dict) -> dict:
    url = "https://api.x.ai/v1/chat/completions"
    headers = {"Authorization": f"Bearer {XAI_API_KEY}", "Content-Type": "application/json"}
    r = requests.post(url, headers=headers, json=payload, timeout=60)
    r.raise_for_status()
    return r.json()

def build_system_prompt(strict: bool = False) -> str:
    base = (
        "–¢—ã –º–æ–¥–Ω—ã–π —Å—Ç–∏–ª–∏—Å—Ç. –ü–æ–¥–±–∏—Ä–∞–π —Å—Ç—Ä–æ–≥–æ 5 –≤–µ—â–µ–π: üëï —Ñ—É—Ç–±–æ–ª–∫–∞, üëñ –¥–∂–∏–Ω—Å—ã, üëü –∫—Ä–æ—Å—Å–æ–≤–∫–∏, üß• –∫—É—Ä—Ç–∫–∞, üéí –∞–∫—Å–µ—Å—Å—É–∞—Ä.\n"
        "–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: Emoji –ù–∞–∑–≤–∞–Ω–∏–µ ‚Äî —Å—Å—ã–ª–∫–∞ (–ø–æ –æ–¥–Ω–æ–π –≤–µ—â–∏ –Ω–∞ —Å—Ç—Ä–æ–∫—É).\n\n"
        "‚ÄºÔ∏è –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å—Å—ã–ª–∫–∞–º:\n"
        "- –°—Å—ã–ª–∫–∞ –¥–æ–ª–∂–Ω–∞ –≤–µ—Å—Ç–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ (product page), –∞ –Ω–µ –Ω–∞ –≥–ª–∞–≤–Ω—É—é –∏–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—é.\n"
        "- –ú–∞–≥–∞–∑–∏–Ω—ã: Zara, H&M, Bershka, ASOS, Lyst, Grailed, Zalando, Levi's, Converse.\n"
        "- –°—Å—ã–ª–∫–∞ –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å product ID –∏–ª–∏ slug (–Ω–∞–ø—Ä–∏–º–µ—Ä: 'productpage', 'p012345', 'id=12345', '/dp/').\n"
        "- –ö–∞—Ç–µ–≥–æ—Ä–∏–∏/–≥–ª–∞–≤–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∑–∞–ø—Ä–µ—â–µ–Ω—ã.\n"
    )
    if strict:
        base += "–°–¢–†–û–ì–û: –≤–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û 5 URL –∫–∞—Ä—Ç–æ—á–µ–∫ —Ç–æ–≤–∞—Ä–æ–≤, –ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É, –Ω–∏–∫–∞–∫–∏—Ö –æ–ø–∏—Å–∞–Ω–∏–π."
    return base

def ask_grok(user_text: str, strict: bool = False, max_search_results: int = 20) -> dict:
    payload = {
        "model": "grok-4",
        "messages": [
            {"role": "system", "content": build_system_prompt(strict=strict)},
            {"role": "user", "content": f"–ü–æ–¥–±–µ—Ä–∏ –∞—É—Ç—Ñ–∏—Ç (—Ñ—É—Ç–±–æ–ª–∫–∞, –¥–∂–∏–Ω—Å—ã, –∫—Ä–æ—Å—Å–æ–≤–∫–∏, –∫—É—Ä—Ç–∫–∞, –∞–∫—Å–µ—Å—Å—É–∞—Ä): {user_text}"}
        ],
        "max_tokens": 600,
        "search_parameters": {
            "mode": "on",
            "return_citations": True,
            "max_search_results": max_search_results,
            "sources": [{"type": "web"}]
        },
        "temperature": 0.15
    }
    logger.info("Grok request strict=%s", strict)
    return grok_call(payload)

# ========== Bot handlers ==========
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    kb = [[InlineKeyboardButton("–ü—Ä–∏–º–µ—Ä: –∫—ç–∂—É–∞–ª", callback_data="casual")],
          [InlineKeyboardButton("–ü–æ–º–æ—â—å", callback_data="help")]]
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –ù–∞–ø–∏—à–∏ —Å—Ç–∏–ª—å, –∏ —è –ø–æ–¥–±–µ—Ä—É 5 —Ä–µ–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–Ω—ã—Ö —Å—Å—ã–ª–æ–∫.", reply_markup=InlineKeyboardMarkup(kb))

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ: –Ω–∞–ø—Ä–∏–º–µ—Ä 'casual –Ω–∞ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å' ‚Äî –≤–µ—Ä–Ω—É 5 —Ç–æ–≤–∞—Ä–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü.")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_text = (update.message.text or "").strip()
    if not user_text:
        await update.message.reply_text("–ù–∞–ø–∏—à–∏, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, —á—Ç–æ –∏—Å–∫–∞—Ç—å (–ø—Ä–∏–º–µ—Ä: 'casual outfit').")
        return

    await update.message.reply_text("–ò—â—É —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ–≤–∞—Ä–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ‚Äî –∑–∞–π–º—ë—Ç –ø–∞—Ä—É —Å–µ–∫—É–Ω–¥...")

    found = []            # list of (url, title)
    tried_urls = []       # raw urls we saw (for logs)
    attempts = 0
    # –ë—É–¥–µ–º –¥–µ–ª–∞—Ç—å –¥–æ 5 –ø–æ–ø—ã—Ç–æ–∫: 1 –æ–±—ã—á–Ω—ã–π, 3 —Å—Ç—Ä–æ–≥–∏—Ö, –ø–æ—Ç–æ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    while len(found) < 5 and attempts < 5:
        strict = attempts >= 1  # –ø–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ - –æ–±—ã—á–Ω–∞—è, –¥–∞–ª–µ–µ strict
        try:
            raw = ask_grok(user_text, strict=strict, max_search_results=20 if strict else 12)
        except Exception as e:
            logger.exception("Grok error")
            await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ø–æ–∏—Å–∫—É, –ø–æ–≤—Ç–æ—Ä—é –ø–æ–ø—ã—Ç–∫—É...")
            attempts += 1
            continue

        # 1) –≤–æ–∑—å–º—ë–º citations (–µ—Å–ª–∏ –µ—Å—Ç—å) ‚Äî –æ–Ω–∏ —á–∞—Å—Ç–æ –±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã
        citations = raw.get("citations") or []
        # 2) –ø–∞—Ä—Å–∏–º –∏–∑ message.content
        choice = (raw.get("choices") or [{}])[0]
        msg = choice.get("message") or {}
        text = msg.get("content") or ""
        text = html.unescape(text or "")
        urls_from_text = extract_urls(text)
        # union with citations
        candidates = []
        for u in citations + urls_from_text:
            cu = clean_and_safe(u) if False else u  # placeholder
            cu = u  # we already cleaned earlier
            if cu and cu not in candidates:
                candidates.append(cu)
        # log
        logger.info("Attempt %s: got %s candidates (citations %s, textUrls %s)", attempts, len(candidates), len(citations), len(urls_from_text))
        logger.info("Candidates sample: %s", candidates[:10])
        tried_urls.extend(candidates)

        # filter candidates -- prefer those that look like product pages
        product_candidates = [u for u in candidates if looks_like_product(u)]
        # If none look like product, keep candidates anyway (we'll validate and maybe fetch titles)
        to_check = product_candidates or candidates

        # validate and fetch titles
        validated = await validate_and_title_batch(to_check, needed=5 - len(found))
        # append unique
        for (u, title) in validated:
            if not any(u == f[0] for f in found):
                found.append((u, title))
                logger.info("Validated product: %s (title=%s)", u, title)
                if len(found) >= 5:
                    break

        # small pause between attempts to avoid rate-limits
        attempts += 1
        if len(found) < 5:
            await asyncio.sleep(0.6)

    # –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë –º–∞–ª–æ ‚Äî –ø–æ–ø—ã—Ç–∞–µ–º—Å—è –≤–∑—è—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Ä–ª—ã –∏–∑ tried_urls –∏ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –∏—Ö (–±–æ–ª–µ–µ —à–∏—Ä–æ–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
    if len(found) < 5 and tried_urls:
        additional_candidates = [u for u in tried_urls if u not in [f[0] for f in found]]
        more = await validate_and_title_batch(additional_candidates, needed=5 - len(found))
        for (u, title) in more:
            if not any(u == f[0] for f in found):
                found.append((u, title))
                if len(found) >= 5:
                    break

    # Final guarantee: –µ—Å–ª–∏ –≤—Å—ë –µ—â—ë –Ω–µ—Ç –Ω–∏ –æ–¥–Ω–æ–π ‚Äî —á–µ—Å—Ç–Ω–æ —Å–æ–æ–±—â–∞–µ–º (–Ω–æ –±–æ—Ç –±—É–¥–µ—Ç –ø—ã—Ç–∞—Ç—å—Å—è –º–Ω–æ–≥–æ —Ä–∞–∑ so should find something)
    if not found:
        await update.message.reply_text("üòî –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –Ω–∏ –æ–¥–Ω–æ–π —Ç–æ–≤–∞—Ä–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã. –ü–æ–ø—Ä–æ–±—É–π —É–∫–∞–∑–∞—Ç—å –±—Ä–µ–Ω–¥/—Ü–µ–ª—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–µ–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä: 'Zara –±–µ–ª–∞—è —Ñ—É—Ç–±–æ–ª–∫–∞').")
        return

    # Prepare message: show emoji + title (or '–¢–æ–≤–∞—Ä') and add InlineKeyboardButtons for each URL
    lines = []
    buttons = []
    for i, (url, title) in enumerate(found[:5]):
        emoji = EMOJIS[i] if i < len(EMOJIS) else "üõçÔ∏è"
        label = title or "–¢–æ–≤–∞—Ä"
        # Limit label length
        if len(label) > 80:
            label = label[:77] + "..."
        lines.append(f"{emoji} {label}\n{url}")
        buttons.append([InlineKeyboardButton(f"{emoji} –û—Ç–∫—Ä—ã—Ç—å", url=url)])

    msg_text = "–í–æ—Ç —Ç–≤–æ–π –∞—É—Ç—Ñ–∏—Ç (—Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ–≤–∞—Ä–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã):\n\n" + "\n\n".join(lines)
    # Send as single message with keyboard, disable web preview so UI not show a big preview (optional)
    await update.message.reply_text(msg_text, reply_markup=InlineKeyboardMarkup(buttons), disable_web_page_preview=True)

# ========== UTIL small helpers ==========
def looks_like_product(url: str) -> bool:
    url_l = url.lower()
    if any(h in url_l for h in PRODUCT_HINTS):
        return True
    try:
        p = requests.utils.urlparse(url).path
        if p and len([s for s in p.split("/") if s]) >= 2:
            return True
    except Exception:
        pass
    return False

def clean_and_safe(u: str) -> str:
    return html.unescape(u).replace("\u200b", "").strip()

# ========== MAIN ==========
def main():
    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    logger.info("Bot starting webhook...")
    app.run_webhook(listen="0.0.0.0", port=PORT, url_path=TELEGRAM_BOT_TOKEN, webhook_url=f"{APP_URL}/{TELEGRAM_BOT_TOKEN}")

if __name__ == "__main__":
    main()
